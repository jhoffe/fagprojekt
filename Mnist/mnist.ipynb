{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import NLLLoss\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.autograd import Variable\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "def show_img(img):\n",
    "    plt.figure()\n",
    "    plt.imshow(img.detach().cpu().numpy().reshape((28, 28)))\n",
    "    plt.show()\n",
    "\n",
    "class CausalConv1d(nn.Conv1d):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size,\n",
    "                 stride=1,\n",
    "                 dilation=1,\n",
    "                 groups=1,\n",
    "                 bias=True):\n",
    "        super(CausalConv1d, self).__init__(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride=stride,\n",
    "            padding=0,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=bias)\n",
    "\n",
    "        self.left_padding = dilation * (kernel_size - 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.pad(x.unsqueeze(2), (self.left_padding, 0, 0, 0)).squeeze(2)\n",
    "\n",
    "        return super(CausalConv1d, self).forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "def receptive_field_size(total_layers, num_cycles, kernel_size,\n",
    "                         dilation=lambda x: 2**x):\n",
    "    \"\"\"Compute receptive field size\n",
    "    Args:\n",
    "        total_layers (int): total layers\n",
    "        num_cycles (int): cycles\n",
    "        kernel_size (int): kernel size\n",
    "        dilation (lambda): lambda to compute dilation factor. ``lambda x : 1``\n",
    "          to disable dilated convolution.\n",
    "    Returns:\n",
    "        int: receptive field size in sample\n",
    "    \"\"\"\n",
    "    assert total_layers % num_cycles == 0\n",
    "    layers_per_cycle = total_layers // num_cycles\n",
    "    dilations = [dilation(i % layers_per_cycle) for i in range(total_layers)]\n",
    "    return (kernel_size - 1) * sum(dilations) + 1\n",
    "\n",
    "class CausalModel(nn.Module):\n",
    "    def __init__(self, input_size=28 * 28, output_size=28 * 28, kernel_size=3, bias=True):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        super(CausalModel, self).__init__()\n",
    "\n",
    "        ch = 256\n",
    "\n",
    "        self.stacks = 2\n",
    "        self.layers = 2\n",
    "        assert self.layers % self.stacks == 0\n",
    "        layers_per_stack = self.layers // self.stacks\n",
    "\n",
    "        self.start_conv = nn.Conv1d(in_channels=1, out_channels=ch, kernel_size=1)\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "\n",
    "        for layer in range(self.layers):\n",
    "            #dilation = 2**(layer % layers_per_stack)\n",
    "            dilation = 1\n",
    "\n",
    "            conv = CausalConv1d(in_channels=ch, out_channels=ch, kernel_size=kernel_size, bias=True, dilation=dilation)\n",
    "            self.conv_layers.append(conv)\n",
    "\n",
    "        self.last_conv_layers = nn.ModuleList([\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(in_channels=ch, out_channels=ch, kernel_size=1),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Conv1d(in_channels=ch, out_channels=2, kernel_size=1)\n",
    "        ])\n",
    "\n",
    "        self.receptive_field = receptive_field_size(self.layers, self.stacks, self.kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.start_conv(x)\n",
    "        for f in self.conv_layers:\n",
    "            x = f(x)\n",
    "\n",
    "        for f in self.last_conv_layers:\n",
    "            x = f(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def incremental_forward(self):\n",
    "        self.eval()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "TRAIN_UPDATES = 30000\n",
    "BATCH_SIZE = 32\n",
    "LR = 3e-5\n",
    "DEVICE = 'cuda' if torch.cuda.device_count() > 0 else 'cpu'\n",
    "CPU_CORES = 4\n",
    "\n",
    "default_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0, 1),\n",
    "    transforms.Lambda(lambda x: x.flatten(start_dim=1))\n",
    "])\n",
    "target_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x > 0.5),\n",
    "    transforms.Lambda(lambda x: x.type(torch.LongTensor).squeeze())\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root=\"./data/mnist\", train=True, transform=default_transform,\n",
    "                                           download=True)\n",
    "val_dataset = torchvision.datasets.MNIST(root=\"./data/mnist\", train=False, transform=default_transform,\n",
    "                                         download=True)\n",
    "train_dataloader = DataLoader(train_dataset, num_workers=CPU_CORES, batch_size=BATCH_SIZE)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NLL=3.240241527557373: 100%|██████████| 1875/1875 [02:24<00:00, 12.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.2415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NLL=3.2369372844696045:  12%|█▏        | 224/1875 [00:18<02:13, 12.41it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [163]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     18\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     20\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m---> 21\u001B[0m     pbar\u001B[38;5;241m.\u001B[39mset_description(desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNLL=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     22\u001B[0m     mean_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\n\u001B[1;32m     23\u001B[0m mean_loss \u001B[38;5;241m=\u001B[39m mean_loss\u001B[38;5;241m/\u001B[39m\u001B[38;5;28mlen\u001B[39m(pbar)\n",
      "File \u001B[0;32m~/anaconda3/envs/fagprojekt/lib/python3.9/site-packages/torch/_tensor.py:663\u001B[0m, in \u001B[0;36mTensor.__format__\u001B[0;34m(self, format_spec)\u001B[0m\n\u001B[1;32m    661\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(Tensor\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__format__\u001B[39m, (\u001B[38;5;28mself\u001B[39m,), \u001B[38;5;28mself\u001B[39m, format_spec)\n\u001B[1;32m    662\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_meta:\n\u001B[0;32m--> 663\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__format__\u001B[39m(format_spec)\n\u001B[1;32m    664\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__format__\u001B[39m(\u001B[38;5;28mself\u001B[39m, format_spec)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = CausalModel(kernel_size=2).cuda()\n",
    "loss_fn = NLLLoss()\n",
    "optimizer = Adam(params=model.parameters(), lr=LR)\n",
    "\n",
    "for epoch in range(5):\n",
    "    print(f\"Epoch: {epoch + 1}\")\n",
    "    pbar = tqdm(train_dataloader)\n",
    "\n",
    "    mean_loss = 0\n",
    "\n",
    "    for x, _ in pbar:\n",
    "        y = target_transform(x).cuda()\n",
    "        yh = model.forward(x.cuda())\n",
    "        log_probs = F.log_softmax(yh)\n",
    "\n",
    "        loss = loss_fn(log_probs, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        pbar.set_description(desc=f\"NLL={loss}\")\n",
    "        mean_loss += loss\n",
    "    mean_loss = mean_loss/len(pbar)\n",
    "    print(mean_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "testmodel = CausalModel(kernel_size=28).cuda()\n",
    "\n",
    "test = model.generate(784)\n",
    "\n",
    "show_img(test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 784])\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x, _ in val_dataloader:\n",
    "    yh = torch.argmax(model.forward(x.cuda()), 1)\n",
    "    print(y.size())\n",
    "\n",
    "    y = target_transform(x)\n",
    "\n",
    "    show_img(y[0, :])\n",
    "    show_img(yh[0, :])\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "data": {
      "text/plain": "OrderedDict([('start_conv.weight',\n              tensor([[[ 0.3490]],\n              \n                      [[ 0.4930]],\n              \n                      [[-0.5022]],\n              \n                      [[-1.0617]],\n              \n                      [[-0.9840]],\n              \n                      [[ 0.4648]],\n              \n                      [[ 1.0151]],\n              \n                      [[-0.6543]],\n              \n                      [[-0.4407]],\n              \n                      [[ 0.8001]],\n              \n                      [[-0.7241]],\n              \n                      [[ 0.9464]],\n              \n                      [[-0.8833]],\n              \n                      [[-0.3246]],\n              \n                      [[-0.3488]],\n              \n                      [[-0.9254]],\n              \n                      [[ 0.9991]],\n              \n                      [[ 0.8848]],\n              \n                      [[ 0.6807]],\n              \n                      [[ 0.5383]],\n              \n                      [[ 0.8034]],\n              \n                      [[ 0.6145]],\n              \n                      [[-0.8786]],\n              \n                      [[ 0.8328]],\n              \n                      [[ 0.6983]],\n              \n                      [[ 0.3337]],\n              \n                      [[ 0.3809]],\n              \n                      [[ 0.8431]],\n              \n                      [[-1.0223]],\n              \n                      [[ 0.1859]],\n              \n                      [[-0.6981]],\n              \n                      [[-0.6836]],\n              \n                      [[ 0.9073]],\n              \n                      [[ 0.3575]],\n              \n                      [[ 0.6472]],\n              \n                      [[ 0.8125]],\n              \n                      [[-0.3991]],\n              \n                      [[-0.9599]],\n              \n                      [[-0.7801]],\n              \n                      [[-0.6724]],\n              \n                      [[ 0.0841]],\n              \n                      [[-0.8880]],\n              \n                      [[ 0.2463]],\n              \n                      [[ 0.3176]],\n              \n                      [[-0.9829]],\n              \n                      [[-0.9177]],\n              \n                      [[ 0.1185]],\n              \n                      [[-0.7593]],\n              \n                      [[-0.7431]],\n              \n                      [[-0.3212]]], device='cuda:0')),\n             ('start_conv.bias',\n              tensor([ 0.7870,  0.5340,  0.4529,  0.8229, -0.8019, -1.0102, -0.0367,  0.2036,\n                       0.9343, -0.1927,  0.7674, -0.3659,  0.3141,  0.9464, -0.5229, -0.9116,\n                       0.0161,  0.2704, -0.8356, -0.3022,  0.4922,  0.9358, -0.5573, -0.2396,\n                       0.9652,  0.2202, -0.0651,  0.6487,  0.9948,  0.1549, -0.7659,  0.4520,\n                      -0.4464, -0.3161,  1.0125,  0.7642, -0.0628,  0.8994,  0.1155, -0.6359,\n                       0.4643, -0.3644,  0.2515, -0.7193,  0.4523, -0.9414, -0.6300, -0.2397,\n                       0.6165,  0.5855], device='cuda:0')),\n             ('conv_layers.0.weight',\n              tensor([[[ 0.0679,  0.0175],\n                       [-0.0701,  0.0289],\n                       [-0.0726,  0.1584],\n                       ...,\n                       [-0.0437,  0.1323],\n                       [-0.0264,  0.1057],\n                       [-0.0065,  0.0900]],\n              \n                      [[ 0.0435, -0.1314],\n                       [-0.0372, -0.0395],\n                       [-0.1168, -0.0192],\n                       ...,\n                       [ 0.0430,  0.1369],\n                       [-0.0636,  0.0529],\n                       [ 0.0209, -0.0246]],\n              \n                      [[-0.0246, -0.1232],\n                       [-0.1248, -0.0429],\n                       [ 0.0498, -0.0860],\n                       ...,\n                       [-0.0364,  0.0066],\n                       [-0.0923,  0.0197],\n                       [ 0.0195, -0.1110]],\n              \n                      ...,\n              \n                      [[-0.0458,  0.0591],\n                       [-0.0659,  0.0148],\n                       [ 0.0403, -0.1113],\n                       ...,\n                       [-0.0882,  0.0376],\n                       [ 0.0318, -0.0639],\n                       [-0.1290, -0.0565]],\n              \n                      [[-0.1172, -0.0203],\n                       [-0.1035,  0.0106],\n                       [-0.0587, -0.1491],\n                       ...,\n                       [ 0.0022, -0.0285],\n                       [-0.0753,  0.0217],\n                       [-0.1010,  0.0278]],\n              \n                      [[ 0.0052, -0.0364],\n                       [-0.0883,  0.1453],\n                       [ 0.0631, -0.1260],\n                       ...,\n                       [-0.0157, -0.1396],\n                       [ 0.0304, -0.1427],\n                       [ 0.0469, -0.0441]]], device='cuda:0')),\n             ('conv_layers.0.bias',\n              tensor([-0.0391, -0.0423,  0.0364,  0.0717, -0.0570, -0.0306,  0.0473, -0.0025,\n                      -0.0297,  0.0688, -0.1088, -0.1015, -0.0129, -0.0614, -0.0126,  0.0172,\n                      -0.0863,  0.0619, -0.0732,  0.1211, -0.0505, -0.0058, -0.1106,  0.0364,\n                       0.0154,  0.1128,  0.0511, -0.1129,  0.0873,  0.0389,  0.0483,  0.0979,\n                      -0.0447, -0.0449,  0.0256,  0.0398,  0.0528,  0.0707, -0.0028, -0.0701,\n                       0.0193, -0.0233, -0.0391, -0.1083,  0.0867,  0.1143,  0.0634, -0.0117,\n                      -0.0678,  0.0792], device='cuda:0')),\n             ('conv_layers.1.weight',\n              tensor([[[-0.0699, -0.1282],\n                       [ 0.0315, -0.1102],\n                       [-0.0618,  0.0090],\n                       ...,\n                       [-0.0678,  0.1502],\n                       [-0.0286,  0.1200],\n                       [ 0.0867,  0.1287]],\n              \n                      [[-0.0551, -0.0933],\n                       [ 0.1196, -0.0908],\n                       [-0.0509, -0.0145],\n                       ...,\n                       [-0.0643,  0.1206],\n                       [-0.0063,  0.1055],\n                       [ 0.0436,  0.1377]],\n              \n                      [[-0.0738,  0.0809],\n                       [ 0.0464,  0.1021],\n                       [-0.1150, -0.1061],\n                       ...,\n                       [-0.0145, -0.0206],\n                       [-0.0807, -0.0789],\n                       [-0.0397,  0.0316]],\n              \n                      ...,\n              \n                      [[-0.0029, -0.0265],\n                       [-0.0081, -0.0621],\n                       [-0.1048, -0.0937],\n                       ...,\n                       [-0.0651, -0.1273],\n                       [ 0.0552, -0.1516],\n                       [ 0.0144, -0.0584]],\n              \n                      [[-0.0166,  0.0165],\n                       [-0.1083,  0.0711],\n                       [ 0.0244,  0.0143],\n                       ...,\n                       [-0.0073, -0.0941],\n                       [-0.1321, -0.0283],\n                       [-0.0595, -0.0252]],\n              \n                      [[ 0.1048, -0.1290],\n                       [-0.0114,  0.0228],\n                       [ 0.0070,  0.0688],\n                       ...,\n                       [ 0.0975,  0.0976],\n                       [ 0.0389,  0.0742],\n                       [-0.0558,  0.1282]]], device='cuda:0')),\n             ('conv_layers.1.bias',\n              tensor([ 0.0238,  0.0583,  0.0890, -0.0519, -0.1211, -0.0547,  0.0316, -0.0527,\n                      -0.0599,  0.1053,  0.0410, -0.0215,  0.0514,  0.0670,  0.1061, -0.0626,\n                      -0.1125,  0.1038,  0.0504,  0.0847,  0.0409,  0.0826,  0.0245, -0.0466,\n                       0.0099, -0.0944,  0.0207, -0.0980, -0.1031,  0.0413, -0.0696, -0.0100,\n                       0.0474, -0.0595,  0.0637,  0.0827,  0.0111,  0.0021, -0.0858,  0.0559,\n                      -0.0608,  0.0351, -0.0531, -0.0938,  0.0851, -0.0356,  0.0731,  0.1332,\n                      -0.0041, -0.1264], device='cuda:0')),\n             ('conv_layers.2.weight',\n              tensor([[[ 0.0731, -0.0312],\n                       [-0.0630, -0.0204],\n                       [-0.1001,  0.0846],\n                       ...,\n                       [-0.0411,  0.0055],\n                       [-0.1154, -0.0678],\n                       [ 0.0619, -0.0892]],\n              \n                      [[ 0.1057, -0.0969],\n                       [-0.0650, -0.0767],\n                       [-0.0652,  0.1657],\n                       ...,\n                       [-0.0802,  0.1767],\n                       [ 0.0877,  0.1406],\n                       [ 0.0693, -0.1636]],\n              \n                      [[ 0.0612,  0.1246],\n                       [-0.0229,  0.1551],\n                       [-0.0480, -0.0625],\n                       ...,\n                       [ 0.0860,  0.0027],\n                       [ 0.0931, -0.1173],\n                       [-0.0735,  0.1619]],\n              \n                      ...,\n              \n                      [[ 0.1234, -0.0978],\n                       [ 0.0514, -0.0163],\n                       [ 0.0113,  0.1188],\n                       ...,\n                       [ 0.0593,  0.0428],\n                       [-0.1039,  0.1053],\n                       [-0.0723, -0.1724]],\n              \n                      [[ 0.0822, -0.0743],\n                       [-0.0047, -0.0547],\n                       [-0.0152,  0.0231],\n                       ...,\n                       [-0.0692, -0.0378],\n                       [ 0.0358, -0.0801],\n                       [-0.0541,  0.0778]],\n              \n                      [[ 0.0152, -0.0260],\n                       [-0.0825, -0.0454],\n                       [ 0.0613,  0.1520],\n                       ...,\n                       [ 0.0471,  0.0958],\n                       [ 0.0235,  0.1315],\n                       [-0.0211, -0.0341]]], device='cuda:0')),\n             ('conv_layers.2.bias',\n              tensor([ 0.0460,  0.0363, -0.0593,  0.0853,  0.0030, -0.0825, -0.0159, -0.0871,\n                       0.0300,  0.0813,  0.0336,  0.0841, -0.1091,  0.0354, -0.0048,  0.0232,\n                       0.0705, -0.0230,  0.0663,  0.0882, -0.1078, -0.0293,  0.0989, -0.0825,\n                      -0.0794,  0.0931,  0.1131, -0.0282,  0.0541, -0.0479, -0.0327, -0.0935,\n                      -0.1070,  0.0652,  0.0397,  0.0413, -0.0023, -0.0825,  0.0014,  0.0679,\n                       0.1157,  0.1039, -0.0566, -0.0564, -0.0531,  0.0211, -0.0180, -0.0561,\n                      -0.1160,  0.0495], device='cuda:0')),\n             ('conv_layers.3.weight',\n              tensor([[[-0.0416,  0.0939],\n                       [-0.0653,  0.0246],\n                       [-0.0318,  0.0761],\n                       ...,\n                       [ 0.0532,  0.0606],\n                       [ 0.0990,  0.0055],\n                       [-0.0405,  0.0307]],\n              \n                      [[-0.1038,  0.0803],\n                       [ 0.0203,  0.1721],\n                       [ 0.0212, -0.1189],\n                       ...,\n                       [-0.0156,  0.0902],\n                       [ 0.0413,  0.0518],\n                       [-0.0471,  0.1107]],\n              \n                      [[ 0.0701,  0.0010],\n                       [ 0.0250, -0.0615],\n                       [-0.0592,  0.0221],\n                       ...,\n                       [ 0.0773,  0.0690],\n                       [-0.0011,  0.0585],\n                       [-0.0804,  0.0234]],\n              \n                      ...,\n              \n                      [[-0.0756, -0.0927],\n                       [-0.0725, -0.1571],\n                       [-0.0082, -0.0381],\n                       ...,\n                       [ 0.0464, -0.0161],\n                       [ 0.0114, -0.0006],\n                       [ 0.0787, -0.0698]],\n              \n                      [[-0.0756, -0.0715],\n                       [-0.0476, -0.0036],\n                       [ 0.0860,  0.0817],\n                       ...,\n                       [-0.0433, -0.0615],\n                       [ 0.0753,  0.0424],\n                       [ 0.0623,  0.0518]],\n              \n                      [[ 0.0704,  0.0115],\n                       [-0.0123, -0.0294],\n                       [-0.0952, -0.0490],\n                       ...,\n                       [ 0.0467, -0.0655],\n                       [-0.0106,  0.0108],\n                       [ 0.0319, -0.0233]]], device='cuda:0')),\n             ('conv_layers.3.bias',\n              tensor([ 0.0693, -0.0670, -0.0680,  0.0792, -0.0425, -0.0627,  0.0860,  0.0203,\n                      -0.0187,  0.0911,  0.0062, -0.0446, -0.1030, -0.0875,  0.0006, -0.0073,\n                       0.0139, -0.0318,  0.0269,  0.0525,  0.0088, -0.0613,  0.0486,  0.0496,\n                      -0.0646, -0.0439,  0.0767, -0.0204,  0.0467, -0.0152,  0.0190, -0.0759,\n                      -0.0304,  0.0924, -0.0511,  0.0094, -0.0938,  0.1046, -0.0589,  0.0297,\n                      -0.0049, -0.0464, -0.0564, -0.0110,  0.0548,  0.0312,  0.0645, -0.0440,\n                       0.0587, -0.1019], device='cuda:0')),\n             ('last_conv_layers.1.weight',\n              tensor([[[-0.0964],\n                       [-0.0952],\n                       [ 0.0691],\n                       ...,\n                       [-0.0202],\n                       [ 0.1094],\n                       [-0.1323]],\n              \n                      [[-0.0281],\n                       [ 0.0269],\n                       [ 0.1260],\n                       ...,\n                       [ 0.0309],\n                       [-0.0665],\n                       [-0.1412]],\n              \n                      [[ 0.0040],\n                       [-0.0864],\n                       [ 0.1285],\n                       ...,\n                       [ 0.1189],\n                       [ 0.0518],\n                       [ 0.0640]],\n              \n                      ...,\n              \n                      [[-0.0013],\n                       [-0.0578],\n                       [ 0.1313],\n                       ...,\n                       [ 0.1726],\n                       [ 0.0430],\n                       [-0.0617]],\n              \n                      [[ 0.0625],\n                       [ 0.1493],\n                       [-0.0135],\n                       ...,\n                       [-0.1039],\n                       [-0.0893],\n                       [ 0.0083]],\n              \n                      [[-0.0802],\n                       [-0.0234],\n                       [ 0.0995],\n                       ...,\n                       [-0.1580],\n                       [-0.1063],\n                       [ 0.0888]]], device='cuda:0')),\n             ('last_conv_layers.1.bias',\n              tensor([ 0.0892, -0.0828,  0.1334, -0.0211,  0.1356, -0.1473,  0.1171, -0.0405,\n                      -0.1245,  0.1314,  0.0668, -0.1629,  0.0403,  0.0972,  0.0807,  0.0555,\n                       0.0353, -0.0331,  0.0018,  0.0704,  0.0094,  0.1245, -0.0507,  0.1309,\n                      -0.0688, -0.0772, -0.0703,  0.1263,  0.0564,  0.0031,  0.0416,  0.0915,\n                       0.0787, -0.0827,  0.0206,  0.1395, -0.0575,  0.0712,  0.1092, -0.0673,\n                      -0.0170,  0.1132, -0.0374, -0.0596, -0.0239,  0.0024, -0.0573,  0.0920,\n                      -0.0898,  0.0654], device='cuda:0')),\n             ('last_conv_layers.3.weight',\n              tensor([[[-0.2194],\n                       [ 0.2297],\n                       [ 0.0557],\n                       [ 0.2018],\n                       [ 0.1782],\n                       [-0.3575],\n                       [ 0.3027],\n                       [-0.0372],\n                       [-0.2702],\n                       [ 0.2977],\n                       [-0.0241],\n                       [-0.2444],\n                       [-0.0221],\n                       [ 0.0897],\n                       [-0.2680],\n                       [ 0.1125],\n                       [-0.1205],\n                       [ 0.0006],\n                       [-0.2915],\n                       [ 0.3167],\n                       [-0.0373],\n                       [ 0.0080],\n                       [ 0.0119],\n                       [ 0.2554],\n                       [ 0.0251],\n                       [ 0.2606],\n                       [ 0.3108],\n                       [ 0.0721],\n                       [ 0.1064],\n                       [ 0.2545],\n                       [ 0.2671],\n                       [-0.3404],\n                       [-0.2216],\n                       [-0.2219],\n                       [ 0.0501],\n                       [-0.0522],\n                       [ 0.2428],\n                       [ 0.1987],\n                       [ 0.1381],\n                       [ 0.1324],\n                       [-0.0244],\n                       [-0.2801],\n                       [-0.3646],\n                       [ 0.1021],\n                       [ 0.3184],\n                       [ 0.1208],\n                       [ 0.0937],\n                       [-0.1879],\n                       [ 0.0213],\n                       [ 0.0631]],\n              \n                      [[ 0.2143],\n                       [-0.2022],\n                       [ 0.2371],\n                       [-0.2624],\n                       [-0.1315],\n                       [-0.3176],\n                       [-0.1843],\n                       [-0.2131],\n                       [-0.0668],\n                       [ 0.0576],\n                       [ 0.1905],\n                       [ 0.0222],\n                       [-0.2584],\n                       [ 0.2924],\n                       [ 0.0454],\n                       [-0.2924],\n                       [ 0.2022],\n                       [-0.1971],\n                       [ 0.0724],\n                       [-0.1301],\n                       [-0.2593],\n                       [ 0.2666],\n                       [-0.2005],\n                       [ 0.0552],\n                       [-0.2649],\n                       [-0.0631],\n                       [ 0.1239],\n                       [ 0.3490],\n                       [-0.2997],\n                       [-0.0827],\n                       [ 0.0166],\n                       [-0.0575],\n                       [ 0.2192],\n                       [ 0.1178],\n                       [ 0.2300],\n                       [-0.2583],\n                       [-0.2311],\n                       [-0.1498],\n                       [-0.2531],\n                       [-0.2822],\n                       [ 0.2259],\n                       [ 0.0407],\n                       [-0.0844],\n                       [-0.2145],\n                       [-0.1020],\n                       [ 0.2979],\n                       [ 0.2598],\n                       [ 0.1501],\n                       [-0.2646],\n                       [-0.2270]]], device='cuda:0')),\n             ('last_conv_layers.3.bias',\n              tensor([0.5467, 0.0425], device='cuda:0'))])"
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}