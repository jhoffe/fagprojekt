{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BCELoss\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "def show_img(img):\n",
    "    plt.figure()\n",
    "    plt.imshow(img.detach().cpu().numpy().reshape((28, 28)))\n",
    "    plt.show()\n",
    "\n",
    "class CausalConv1d(nn.Conv1d):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size,\n",
    "                 stride=1,\n",
    "                 dilation=1,\n",
    "                 groups=1,\n",
    "                 bias=True):\n",
    "        super(CausalConv1d, self).__init__(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride=stride,\n",
    "            padding=0,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=bias)\n",
    "\n",
    "        self.left_padding = dilation * (kernel_size - 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.pad(x.unsqueeze(2), (self.left_padding, 0, 0, 0)).squeeze(2)\n",
    "\n",
    "        return super(CausalConv1d, self).forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def receptive_field_size(total_layers, num_cycles, kernel_size,\n",
    "                         dilation=lambda x: 2**x):\n",
    "    \"\"\"Compute receptive field size\n",
    "    Args:\n",
    "        total_layers (int): total layers\n",
    "        num_cycles (int): cycles\n",
    "        kernel_size (int): kernel size\n",
    "        dilation (lambda): lambda to compute dilation factor. ``lambda x : 1``\n",
    "          to disable dilated convolution.\n",
    "    Returns:\n",
    "        int: receptive field size in sample\n",
    "    \"\"\"\n",
    "    assert total_layers % num_cycles == 0\n",
    "    layers_per_cycle = total_layers // num_cycles\n",
    "    dilations = [dilation(i % layers_per_cycle) for i in range(total_layers)]\n",
    "    return (kernel_size - 1) * sum(dilations) + 1\n",
    "\n",
    "class CausalModel(nn.Module):\n",
    "    def __init__(self, input_size=28 * 28, output_size=28 * 28, kernel_size=3, bias=True, dropout=0.4):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        super(CausalModel, self).__init__()\n",
    "\n",
    "        ch = 50\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.causal_conv = CausalConv1d(in_channels=1, out_channels=ch, kernel_size=kernel_size, bias=bias)\n",
    "        self.conv_1 = nn.Conv1d(in_channels=ch, out_channels=ch, kernel_size=kernel_size, bias=bias, padding=\"same\")\n",
    "        self.conv_2 = nn.Conv1d(in_channels=ch, out_channels=ch, kernel_size=kernel_size, bias=bias, padding=\"same\")\n",
    "        self.end_conv = nn.Conv1d(in_channels=ch, out_channels=2, kernel_size=1, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.causal_conv(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv_1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv_2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.sigmoid(self.end_conv(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def incremental_forward(self):\n",
    "        self.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "TRAIN_UPDATES = 30000\n",
    "BATCH_SIZE = 32\n",
    "LR = 3e-3\n",
    "DEVICE = 'cuda' if torch.cuda.device_count() > 0 else 'cpu'\n",
    "CPU_CORES = 4\n",
    "\n",
    "default_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0, 1),\n",
    "    transforms.Lambda(lambda x: x.flatten(start_dim=1))\n",
    "])\n",
    "target_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x > 0.5),\n",
    "    transforms.Lambda(lambda x: x.type(torch.LongTensor).squeeze()),\n",
    "    transforms.Lambda(lambda x: F.one_hot(x, num_classes=2).permute([0, 2, 1]).float())\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root=\"./data/mnist\", train=True, transform=default_transform,\n",
    "                                           download=True)\n",
    "val_dataset = torchvision.datasets.MNIST(root=\"./data/mnist\", train=False, transform=default_transform,\n",
    "                                         download=True)\n",
    "train_dataloader = DataLoader(train_dataset, num_workers=CPU_CORES, batch_size=BATCH_SIZE)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BCELoss=1.688137412071228: 100%|██████████| 1875/1875 [00:22<00:00, 83.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BCELoss=1.6882797479629517: 100%|██████████| 1875/1875 [00:22<00:00, 83.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BCELoss=1.6880676746368408: 100%|██████████| 1875/1875 [00:21<00:00, 85.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BCELoss=1.6881195306777954: 100%|██████████| 1875/1875 [00:21<00:00, 85.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BCELoss=1.688354730606079: 100%|██████████| 1875/1875 [00:22<00:00, 84.63it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6830, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = CausalModel(kernel_size=3).cuda()\n",
    "loss_fn = BCELoss()\n",
    "optimizer = Adam(params=model.parameters(), lr=LR)\n",
    "\n",
    "for epoch in range(5):\n",
    "    print(f\"Epoch: {epoch + 1}\")\n",
    "    pbar = tqdm(train_dataloader)\n",
    "\n",
    "    mean_loss = 0\n",
    "\n",
    "    for x, _ in pbar:\n",
    "        y = target_transform(x).cuda()\n",
    "        yh = model.forward(x.cuda())\n",
    "        probs = F.softmax(yh)\n",
    "\n",
    "        loss = loss_fn(probs, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        pbar.set_description(desc=f\"BCELoss={loss}\")\n",
    "        mean_loss += loss\n",
    "    mean_loss = mean_loss/len(pbar)\n",
    "    print(mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "testmodel = CausalModel(kernel_size=28).cuda()\n",
    "\n",
    "test = model.generate(784)\n",
    "\n",
    "show_img(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          2.0988e-26, 0.0000e+00]],\n",
      "\n",
      "        [[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 6.4493e-18]],\n",
      "\n",
      "        [[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [2.7348e-12, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 9.9832e-01],\n",
      "         [0.0000e+00, 2.5173e-25, 0.0000e+00,  ..., 8.4740e-15,\n",
      "          2.1334e-26, 2.4956e-04]]], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "torch.Size([32, 784])\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x, _ in val_dataloader:\n",
    "    print(model.forward(x.cuda()))\n",
    "    yh = torch.argmax(model.forward(x.cuda()), 1)\n",
    "    print(yh.size())\n",
    "\n",
    "    y = target_transform(x).argmax(1).unsqueeze(1)\n",
    "\n",
    "    show_img(y[0, :])\n",
    "    show_img(yh[0, :])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9999e-01, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n          1.0000e+00, 1.0000e+00, 1.0000e+00],\n         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9414e-07, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 1.4476e-20]]], device='cuda:0',\n       grad_fn=<SigmoidBackward0>)"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(torch.tensor([[[0] * 28 * 6]]).cuda().float())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}